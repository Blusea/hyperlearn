

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>hyperlearn package &mdash; HyperLearn 1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="next" title="hyperlearn.base" href="../base.html" />
    <link rel="prev" title="hyperlearn" href="modules.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> HyperLearn
          

          
          </a>

          
            
            
              <div class="version">
                0.0.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">hyperlearn</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">hyperlearn package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-hyperlearn.base">hyperlearn.base module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-hyperlearn.linalg">hyperlearn.linalg module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-hyperlearn.numba">hyperlearn.numba module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-hyperlearn.utils">hyperlearn.utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hyperlearn-random-module">hyperlearn.random module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hyperlearn-randomized-base-module">hyperlearn.randomized.base module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hyperlearn-randomized-linalg-module">hyperlearn.randomized.linalg module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-hyperlearn">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../base.html">hyperlearn.base</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg.html">hyperlearn.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html#contact">Contact</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">HyperLearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="modules.html">hyperlearn</a> &raquo;</li>
        
      <li>hyperlearn package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/source/hyperlearn.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="hyperlearn-package">
<h1>hyperlearn package<a class="headerlink" href="#hyperlearn-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-hyperlearn.base">
<span id="hyperlearn-base-module"></span><h2>hyperlearn.base module<a class="headerlink" href="#module-hyperlearn.base" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="hyperlearn.base.arg_process">
<code class="descclassname">hyperlearn.base.</code><code class="descname">arg_process</code><span class="sig-paren">(</span><em>x</em>, <em>square</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/base.html#arg_process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.base.arg_process" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.base.available_memory">
<code class="descclassname">hyperlearn.base.</code><code class="descname">available_memory</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/base.html#available_memory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.base.available_memory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="class">
<dt id="hyperlearn.base.blas">
<em class="property">class </em><code class="descclassname">hyperlearn.base.</code><code class="descname">blas</code><span class="sig-paren">(</span><em>function</em>, <em>left=''</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/base.html#blas"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.base.blas" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>[Added 14/11/18]
Get a BLAS function based on the dtype(X). Acts like Scipy&#8217;s get blas function.</p>
<p>function:       String for blas function eg: &#8220;getrf&#8221;</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.base.f_same_memory">
<code class="descclassname">hyperlearn.base.</code><code class="descname">f_same_memory</code><span class="sig-paren">(</span><em>n</em>, <em>p</em><span class="sig-paren">)</span><a class="headerlink" href="#hyperlearn.base.f_same_memory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.base.isComplex">
<code class="descclassname">hyperlearn.base.</code><code class="descname">isComplex</code><span class="sig-paren">(</span><em>dtype</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/base.html#isComplex"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.base.isComplex" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="class">
<dt id="hyperlearn.base.lapack">
<em class="property">class </em><code class="descclassname">hyperlearn.base.</code><code class="descname">lapack</code><span class="sig-paren">(</span><em>function</em>, <em>numba=None</em>, <em>turbo=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/base.html#lapack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.base.lapack" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>[Added 14/11/18]
Get a LAPACK function based on the dtype(X). Acts like Scipy&#8217;s get lapack function.</p>
<p>function:       String for lapack function eg: &#8220;getrf&#8221;
turbo:          Boolean to indicate if float32 can be used.
numba:          String for numba function.</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.base.memory">
<code class="descclassname">hyperlearn.base.</code><code class="descname">memory</code><span class="sig-paren">(</span><em>shape</em>, <em>dtype</em>, <em>memcheck</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/base.html#memory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.base.memory" title="Permalink to this definition">¶</a></dt>
<dd><p>[Edited 18/11/18 Slightly faster]
Checks if an operation on a matrix is within memory bounds.</p>
<p>X:                      Input matrix
dtype:          Input datatype(matrix)
memcheck:       lambda n,p: ... function or f(n,p)</p>
<p>need:           Total memory required for operation
surplus:        Boolean - True means within memory bounds.</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.base.process">
<code class="descclassname">hyperlearn.base.</code><code class="descname">process</code><span class="sig-paren">(</span><em>f=None</em>, <em>memcheck=None</em>, <em>square=False</em>, <em>fractional=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/base.html#process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.base.process" title="Permalink to this definition">¶</a></dt>
<dd><p>[Added 14/11/18] [Edited 18/11/18 for speed]
[Edited 25/11/18 Array deprecation of unicode]
[Edited 27/11/18 Allows support for n_components]
[Edited 4/12/18 Supports Fast JLT methods]
Decorator onto HyperLearn functions. Does 2 things:
1. Convert datatypes to appropriate ones
2. Convert matrices to arrays
3. (Optional) checks memory bounds.</p>
<p>f:                      The function to be decorated
memcheck:       lambda n,p: ... function or f(n,p)
fractional:     Whether to change float n_components to ints</p>
</dd></dl>

</div>
<div class="section" id="module-hyperlearn.linalg">
<span id="hyperlearn-linalg-module"></span><h2>hyperlearn.linalg module<a class="headerlink" href="#module-hyperlearn.linalg" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="hyperlearn.linalg.cho_inv">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">cho_inv</code><span class="sig-paren">(</span><em>X</em>, <em>turbo=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#cho_inv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.cho_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes an inverse to the Cholesky Decomposition.
[Added 17/11/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Upper Triangular Cholesky Factor U. Use cholesky first.</em>)</li>
<li><strong>turbo</strong> (<em>Boolean to use float32, rather than more accurate float64.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>inv(U)</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Upper Triangular Inverse(X)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.cho_solve">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">cho_solve</code><span class="sig-paren">(</span><em>X</em>, <em>rhs</em>, <em>alpha=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#cho_solve"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.cho_solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Given U from a cholesky decompostion and a RHS, find a least squares
solution.
[Added 15/11/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Cholesky Factor. Use cholesky first.</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6</em>)</li>
<li><strong>turbo</strong> (<em>Boolean to use float32, rather than more accurate float64.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>U</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Upper triangular cholesky factor (U)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.cholesky">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">cholesky</code><span class="sig-paren">(</span><em>X</em>, <em>alpha=None</em>, <em>overwrite=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#cholesky"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.cholesky" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses Epsilon Jitter Solver to compute the Cholesky Decomposition
until success. Default alpha ridge regularization = 1e-6.
[Added 15/11/18] [Edited 16/11/18 Numpy is slower. Uses LAPACK only]
[Edited 18/11/18 Uses universal &#8220;do_until_success&#8221;]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Matrix to be decomposed. Has to be symmetric.</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to inplace change data.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>U</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Upper triangular cholesky factor (U)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.dot">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">dot</code><span class="sig-paren">(</span><em>A</em>, <em>B</em>, <em>C</em>, <em>message=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#dot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.dot" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements fast matrix multiplication of 3 matrices X = ABC
From left: X = (AB)C. From right: X = A(BC). This function
calculates which is faster, and outputs the result.
[Added 10/12/18] [Edited 13/12/18 Added left or right statement]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>A</strong> (<em>First matrix</em>)</li>
<li><strong>B</strong> (<em>Multiplied with 2nd matrix</em>)</li>
<li><strong>C</strong> (<em>Multiplied with 3rd matrix</em>)</li>
<li><strong>message</strong> (<em>Default = False. If True, doesn&#8217;t output result, but</em>) &#8211; outputs TRUE if left to right, else FALSE right to left.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(A&#64;B&#64;C or message)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.eig">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">eig</code><span class="sig-paren">(</span><em>X</em>, <em>U_decision=False</em>, <em>alpha=None</em>, <em>turbo=True</em>, <em>svd=False</em>, <em>n_jobs=1</em>, <em>conjugate=True</em>, <em>overwrite=False</em>, <em>use_svd=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#eig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.eig" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns sorted eigenvalues and eigenvectors from large to small of
a general matrix X. Follows SVD convention. Also flips signs of
eigenvectors using svd_flip. Uses the Epsilon Jitter
Algorithm to guarantee convergence. Allows Ridge Regularization
default 1e-6.</p>
<p>According to [<cite>Matrix Computations, Third Edition, G. Holub and C.
Van Loan, Chapter 5, section 5.4.4, pp 252-253.</cite>], QR is better if
n &gt;= 5/3p. In Modern Big Data Algorithms, I find QR is better for
all n &gt; p.
[Added 21/11/18] [Edited 22/11/18 with turbo -&gt; approximate
eigendecomposition when p &gt;&gt; n] [Edited 24/11/18 Added Complex Support]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General Matrix.</em>)</li>
<li><strong>U_decision</strong> (<em>Always set to False. Can choose None for no swapping.</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6.</em>)</li>
<li><strong>turbo</strong> (<em>If True, if p &gt;&gt; n, then will output approximate eigenvectors</em>) &#8211; where V = (X.T &#64; U) / sqrt(W)</li>
<li><strong>svd</strong> (<em>Returns sqrt(W) and V.T</em>)</li>
<li><strong>n_jobs</strong> (<em>Whether to use more &gt;= 1 CPU</em>)</li>
<li><strong>conjugate</strong> (<em>Whether to inplace conjugate but inplace return original.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to conjugate transpose inplace.</em>)</li>
<li><strong>use_svd</strong> (<em>Use SVD instead of EIGH (slower, but more robust)</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>W</strong> (<em>Eigenvalues</em>)</li>
<li><strong>V</strong> (<em>Eigenvectors</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.eigh">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">eigh</code><span class="sig-paren">(</span><em>X</em>, <em>U_decision=False</em>, <em>alpha=None</em>, <em>svd=False</em>, <em>n_jobs=1</em>, <em>overwrite=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#eigh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.eigh" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns sorted eigenvalues and eigenvectors from large to small of
a symmetric square matrix X. Follows SVD convention. Also flips
signs of eigenvectors using svd_flip. Uses the Epsilon Jitter
Algorithm to guarantee convergence. Allows Ridge Regularization
default 1e-6.
[Added 21/11/18] [Edited 24/11/18 Added Complex Support, Eigh alpha
set to 0 since Eigh errors are rare.]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Symmetric Square Matrix.</em>)</li>
<li><strong>U_decision</strong> (<em>Always set to False. Can choose None for no swapping.</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6.</em>)</li>
<li><strong>svd</strong> (<em>Returns sqrt(W) and V.T</em>)</li>
<li><strong>n_jobs</strong> (<em>Whether to use more &gt;= 1 CPU</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to directly alter the original matrix.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>W</strong> (<em>Eigenvalues</em>)</li>
<li><strong>V</strong> (<em>Eigenvectors</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.eigh_lwork">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">eigh_lwork</code><span class="sig-paren">(</span><em>dtype</em>, <em>byte</em>, <em>n</em>, <em>p</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#eigh_lwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.eigh_lwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the work required for EIGH (syevr, syevd, heevr, heevd)
SYEVD = 1 + 6n + 2n^2
SYEVR = 26n
HEEVD = 2n + n^2
HEEVR = 2n</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.lu">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">lu</code><span class="sig-paren">(</span><em>X</em>, <em>L_only=False</em>, <em>U_only=False</em>, <em>overwrite=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#lu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.lu" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the pivoted LU decomposition of a matrix. Optional to output
only L or U components with minimal memory copying.
[Added 16/11/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Matrix to be decomposed. Can be retangular.</em>)</li>
<li><strong>L_only</strong> (<em>Output only L.</em>)</li>
<li><strong>U_only</strong> (<em>Output only U.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to directly alter the original matrix.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(L,U) or (L) or (U)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.matmul">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">matmul</code><span class="sig-paren">(</span><em>pattern</em>, <em>X</em>, <em>Y=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#matmul"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.matmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Using BLAS routines GEMM, SYRK, SYMM, multiplies 2 matrices together
assuming X has some special structure or the output is special. Supports
symmetric constructions: X.H &#64; X and X &#64; X.H; symmetric multiplies:
S &#64; Y.H and Y.H &#64; S where S is a symmetric matrix; general multiplies:
X &#64; Y and X.H &#64; Y.
[Added 28/11/18 Changed from transpose since it didn&#8217;t work]
[Edited 1/12/18 Added S &#64; Y]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>pattern</strong> (<em>Can include: X.H &#64; X | X &#64; X.H | S &#64; Y.H |</em>) &#8211; Y.H &#64; S | X &#64; Y | X.H &#64; Y | S &#64; Y</li>
<li><strong>X</strong> (<em>Compulsory left side matrix.</em>)</li>
<li><strong>Y</strong> (<em>Optional right side matrix.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>out</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Special matrix output according to pattern.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.pinv">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">pinv</code><span class="sig-paren">(</span><em>X</em>, <em>alpha=None</em>, <em>overwrite=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#pinv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.pinv" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the inverse of a general Matrix using SVD. Uses the Epsilon Jitter
Algorithm to guarantee convergence. Allows Ridge Regularization - default 1e-6.
[Added 21/11/18] [Edited 23/11/18 Added Complex support]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Upper Triangular Cholesky Factor U. Use cholesky.</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to directly alter the original matrix.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>pinv(X)</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Pseudoinverse of X. Allows pinv(X) &#64; X = I.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.pinvc">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">pinvc</code><span class="sig-paren">(</span><em>X</em>, <em>alpha=None</em>, <em>turbo=True</em>, <em>overwrite=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#pinvc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.pinvc" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the Pseudoinverse of the matrix X using Cholesky Decomposition.
Fastest pinv(X) possible, and uses the Epsilon Jitter Algorithm to
guarantee convergence. Allows Ridge Regularization - default 1e-6.
[Added 17/11/18] [Edited 18/11/18 for speed - uses more BLAS]
[Edited 23/11/18 Added Complex support]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General matrix X.</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6</em>)</li>
<li><strong>turbo</strong> (<em>Boolean to use float32, rather than more accurate float64.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to overwrite intermmediate results. Will cause</em>) &#8211; alpha to be increased by a factor of 10.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>pinv(X)</strong> &#8211; &#64; pinv(X) = I for p &gt; n.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Pseudoinverse of X. Allows pinv(X) &#64; X = I if n &gt;= p or X</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.pinvch">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">pinvch</code><span class="sig-paren">(</span><em>X</em>, <em>alpha=None</em>, <em>turbo=True</em>, <em>overwrite=False</em>, <em>reflect=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#pinvch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.pinvch" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the inverse of a square Hermitian Matrix using Cholesky
Decomposition. Uses the Epsilon Jitter Algorithm to guarantee convergence.
Allows Ridge Regularization - default 1e-6.
[Added 19/11/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Upper Symmetric Matrix X</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6</em>)</li>
<li><strong>turbo</strong> (<em>Boolean to use float32, rather than more accurate float64.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to overwrite X inplace with pinvh.</em>)</li>
<li><strong>reflect</strong> (<em>Output full matrix or 1/2 triangular</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>pinv(X)</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Pseudoinverse of X. Allows pinv(X) &#64; X = I.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.pinvh">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">pinvh</code><span class="sig-paren">(</span><em>X</em>, <em>alpha=None</em>, <em>turbo=True</em>, <em>overwrite=False</em>, <em>reflect=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#pinvh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.pinvh" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the inverse of a square Hermitian Matrix using Eigendecomposition.
Uses the Epsilon Jitter Algorithm to guarantee convergence.
Allows Ridge Regularization - default 1e-6.
[Added 19/11/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Upper Symmetric Matrix X</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6</em>)</li>
<li><strong>turbo</strong> (<em>Boolean to use float32, rather than more accurate float64.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to overwrite X inplace with pinvh.</em>)</li>
<li><strong>reflect</strong> (<em>Output full matrix or 1/2 triangular</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>pinv(X)</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Pseudoinverse of X. Allows pinv(X) &#64; X = I.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.pinvl">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">pinvl</code><span class="sig-paren">(</span><em>X</em>, <em>alpha=None</em>, <em>turbo=True</em>, <em>overwrite=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#pinvl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.pinvl" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the pseudoinverse of a square matrix X using LU Decomposition.
Notice, it&#8217;s much faster to use pinvc (Choleksy Inverse).
[Added 18/11/18] [Edited 26/11/18 Fixed ridge regularization]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Matrix to be decomposed. Must be square.</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6</em>)</li>
<li><strong>turbo</strong> (<em>Boolean to use float32, rather than more accurate float64.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to directly alter the original matrix.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>pinv(X)</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Pseudoinverse of X. Allows pinv(X) &#64; X = I = X &#64; pinv(X)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.qr">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">qr</code><span class="sig-paren">(</span><em>X</em>, <em>Q_only=False</em>, <em>R_only=False</em>, <em>overwrite=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#qr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.qr" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the reduced economic QR Decomposition of a matrix. Optional
to output only Q or R.
[Added 16/11/18] [Edited 28/11/18 Complex support]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Matrix to be decomposed. Can be retangular.</em>)</li>
<li><strong>Q_only</strong> (<em>Output only Q.</em>)</li>
<li><strong>R_only</strong> (<em>Output only R.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to directly alter the original matrix.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(Q,R) or (Q) or (R)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.svd">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">svd</code><span class="sig-paren">(</span><em>X</em>, <em>U_decision=False</em>, <em>n_jobs=1</em>, <em>conjugate=True</em>, <em>overwrite=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#svd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.svd" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Singular Value Decomposition of a general matrix providing
X = U S VT. Notice VT (V transpose) is returned, and not V.
Also, by default, the signs of U and VT are swapped so that VT has the
sign of the maximum item as positive.</p>
<p>HyperLearn&#8217;s SVD is optimized dramatically due to the findings made in
Modern Big Data Algorithms. If p/n &gt;= 0.001, then GESDD is used. Else,
GESVD is used. Also, svd(XT) is used if it&#8217;s faster, bringing the complexity
to O( min(np^2, n^2p) ).
[Added 19/11/18] [Edited 23/11/18 Added Complex support]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Matrix to be decomposed. General matrix.</em>)</li>
<li><strong>U_decision</strong> (<em>Default = False. If True, uses max from U. If None. don&#8217;t flip.</em>)</li>
<li><strong>n_jobs</strong> (<em>Whether to use more &gt;= 1 CPU</em>)</li>
<li><strong>conjugate</strong> (<em>Whether to inplace conjugate but inplace return original.</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to conjugate transpose inplace.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>U</strong> (<em>Orthogonal Left Eigenvectors</em>)</li>
<li><strong>S</strong> (<em>Descending Singular Values</em>)</li>
<li><strong>VT</strong> (<em>Orthogonal Right Eigenvectors</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.svd_lwork">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">svd_lwork</code><span class="sig-paren">(</span><em>dtype</em>, <em>byte</em>, <em>n</em>, <em>p</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#svd_lwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.svd_lwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the work required for SVD (gesdd, gesvd)</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.linalg.transpose">
<code class="descclassname">hyperlearn.linalg.</code><code class="descname">transpose</code><span class="sig-paren">(</span><em>X</em>, <em>overwrite=True</em>, <em>dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/linalg.html#transpose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.linalg.transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Provides X.T if dtype == float, else X.H (Conjugate transpose)
[Added 23/11/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Matrix to be decomposed. Has to be symmetric.</em>)</li>
<li><strong>Overwrite</strong> (<em>If overwritten, then inplace operation.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X.T or X.H</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Conjugate Tranpose (X)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-hyperlearn.numba">
<span id="hyperlearn-numba-module"></span><h2>hyperlearn.numba module<a class="headerlink" href="#module-hyperlearn.numba" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="hyperlearn.numba.arange">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">arange</code><span class="sig-paren">(</span><em>size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#arange"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.arange" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.eigh">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">eigh</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#eigh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.eigh" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.isComplex">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">isComplex</code><span class="sig-paren">(</span><em>dtype</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#isComplex"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.isComplex" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.jit">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">jit</code><span class="sig-paren">(</span><em>f=None</em>, <em>parallel=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#jit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.jit" title="Permalink to this definition">¶</a></dt>
<dd><p>[Added 14/11/2018] [Edited 17/11/2018 Auto add n_jobs argument to functions]
Decorator onto Numba NJIT compiled code.</p>
<p>function:   Function to decorate
parallel:   If true, sets cache automatically to false</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.lstsq">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">lstsq</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#lstsq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.lstsq" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.maximum">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">maximum</code><span class="sig-paren">(</span><em>X</em>, <em>i</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#maximum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.maximum" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.mean">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">mean</code><span class="sig-paren">(</span><em>X</em>, <em>axis=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#mean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.minimum">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">minimum</code><span class="sig-paren">(</span><em>X</em>, <em>i</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#minimum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.minimum" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.norm">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">norm</code><span class="sig-paren">(</span><em>v</em>, <em>d=2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.pinv">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">pinv</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#pinv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.pinv" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.qr">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">qr</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#qr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.qr" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.sign">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">sign</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#sign"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.sign" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.svd">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">svd</code><span class="sig-paren">(</span><em>X</em>, <em>full_matrices=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#svd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.svd" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.numba.uint">
<code class="descclassname">hyperlearn.numba.</code><code class="descname">uint</code><span class="sig-paren">(</span><em>i</em>, <em>array=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/numba.html#uint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.numba.uint" title="Permalink to this definition">¶</a></dt>
<dd><p>[Added 14/11/2018]
Outputs a small array with the correct dtype that minimises
memory usage for storing the maximal number of elements of
size i</p>
<p>i:          Size of maximal elements you want to store</p>
</dd></dl>

</div>
<div class="section" id="module-hyperlearn.utils">
<span id="hyperlearn-utils-module"></span><h2>hyperlearn.utils module<a class="headerlink" href="#module-hyperlearn.utils" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="hyperlearn.utils.L_process">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">L_process</code><span class="sig-paren">(</span><em>n</em>, <em>p</em>, <em>L</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#L_process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.L_process" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.U_process">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">U_process</code><span class="sig-paren">(</span><em>A</em>, <em>size</em>, <em>alpha</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#U_process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.U_process" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.add_jitter">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">add_jitter</code><span class="sig-paren">(</span><em>X</em>, <em>size</em>, <em>alpha</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#add_jitter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.add_jitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Epsilon Jitter Algorithm from Modern Big Data Algorithms. Forces certain
algorithms to converge via ridge regularization.
[Added 15/11/18] [Edited 25/11/2018 for floating point errors]</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.amax_numb_0">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">amax_numb_0</code><span class="sig-paren">(</span><em>X</em>, <em>n</em>, <em>p</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#amax_numb_0"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.amax_numb_0" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.amax_numb_0c">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">amax_numb_0c</code><span class="sig-paren">(</span><em>X</em>, <em>n</em>, <em>p</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#amax_numb_0c"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.amax_numb_0c" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.amax_numb_1">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">amax_numb_1</code><span class="sig-paren">(</span><em>X</em>, <em>n</em>, <em>p</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#amax_numb_1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.amax_numb_1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.amax_numb_1c">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">amax_numb_1c</code><span class="sig-paren">(</span><em>X</em>, <em>n</em>, <em>p</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#amax_numb_1c"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.amax_numb_1c" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.col_norm">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">col_norm</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#col_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.col_norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.do_until_success">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">do_until_success</code><span class="sig-paren">(</span><em>f</em>, <em>epsilon_f</em>, <em>size</em>, <em>overwrite=False</em>, <em>alpha=None</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#do_until_success"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.do_until_success" title="Permalink to this definition">¶</a></dt>
<dd><p>Epsilon Jitter Algorithm from Modern Big Data Algorithms. Forces certain
algorithms to converge via ridge regularization.
[Added 15/11/18] [Edited 25/11/18 Fixed Alpha setting, can now run in
approx 1 - 2 runs] [Edited 26/11/18 99% rounded accuracy in 1 run]
[Edited 14/12/18 Some overwrite errors]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>f</strong> (<em>Function for solver</em>)</li>
<li><strong>epsilon_f</strong> (<em>How to add epsilon</em>)</li>
<li><strong>size</strong> (<em>Argument for epsilon_f</em>)</li>
<li><strong>overwrite</strong> (<em>Whether to overwrite data matrix</em>)</li>
<li><strong>alpha</strong> (<em>Ridge regularizer - default = 1e-6</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.eig_condition">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">eig_condition</code><span class="sig-paren">(</span><em>X</em>, <em>W</em>, <em>V</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#eig_condition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.eig_condition" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.frobenius_norm">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">frobenius_norm</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#frobenius_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.frobenius_norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.gram_schmidt">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">gram_schmidt</code><span class="sig-paren">(</span><em>X</em>, <em>P</em>, <em>n</em>, <em>k</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#gram_schmidt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.gram_schmidt" title="Permalink to this definition">¶</a></dt>
<dd><p>Modified stable Gram Schmidt process.
Gram-Schmidt Orthogonalization
Instructor: Ana Rita Pires (MIT 18.06SC)</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.normA">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">normA</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#normA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.normA" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.reflect">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">reflect</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#reflect"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.reflect" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.row_norm">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">row_norm</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#row_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.row_norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.sign_max">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">sign_max</code><span class="sig-paren">(</span><em>X</em>, <em>axis=0</em>, <em>n_jobs=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#sign_max"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.sign_max" title="Permalink to this definition">¶</a></dt>
<dd><p>[Added 19/11/2018] [Edited 24/11/2018 Uses NUMBA]
Returns the sign of the maximum absolute value of an axis of X.</p>
<p>X:          Matrix X to be processed. Must be 2D array.
axis:       Default = 0. 0 = column-wise. 1 = row-wise.
n_jobs:     Default = 1. Uses multiple CPUs if n*p &gt; 20,000^2.</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.svd_condition">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">svd_condition</code><span class="sig-paren">(</span><em>U</em>, <em>S</em>, <em>VT</em>, <em>alpha=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#svd_condition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.svd_condition" title="Permalink to this definition">¶</a></dt>
<dd><p>[Added 21/11/2018]
Uses Scipy&#8217;s SVD condition number calculation to improve pseudoinverse
stability. Uses (1e3, 1e6) * eps(S) * S[0] as the condition number.
Everythimg below cond is set to 0.</p>
<p>U:          U matrix from SVD
S:          S diagonal array from SVD
VT:         VT matrix (V transpose) from SVD
alpha:      Default = None. Ridge regularization</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.svd_flip">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">svd_flip</code><span class="sig-paren">(</span><em>U=None</em>, <em>VT=None</em>, <em>U_decision=False</em>, <em>n_jobs=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#svd_flip"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.svd_flip" title="Permalink to this definition">¶</a></dt>
<dd><p>[Added 19/11/2018] [Edited 24/11/2018 Uses NUMBA]
Flips the signs of U and VT from a SVD or eigendecomposition.
Default opposite to Sklearn&#8217;s U decision. HyperLearn uses
the maximum of rows of VT.</p>
<p>U:          U matrix from SVD
VT:         VT matrix (V transpose) from SVD
U_decision: Default = False. If True, uses max from U.</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.utils.triu">
<code class="descclassname">hyperlearn.utils.</code><code class="descname">triu</code><span class="sig-paren">(</span><em>n</em>, <em>p</em>, <em>U</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/utils.html#triu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.utils.triu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="hyperlearn-random-module">
<h2>hyperlearn.random module<a class="headerlink" href="#hyperlearn-random-module" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-hyperlearn.random"></span><dl class="function">
<dt id="hyperlearn.random.normal">
<code class="descclassname">hyperlearn.random.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>mean</em>, <em>std</em>, <em>shape</em>, <em>dtype=&lt;class 'numpy.float32'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/random.html#normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.random.normal" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces pseudo-random normal numbers with mean and std.
Notice much more memory efficient than Numpy, as provides
a DTYPE argument (float32 supported).
[Added 24/11/2018]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>mean</strong> (<em>Mean of distribution</em>)</li>
<li><strong>std</strong> (<em>Standard Deviation o distribution.</em>)</li>
<li><strong>shape</strong> (<em>Final shape of random matrix</em>)</li>
<li><strong>dtype</strong> (<em>Data type: supports any type</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Random Vector or Matrix</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.random.random">
<code class="descclassname">hyperlearn.random.</code><code class="descname">random</code><span class="sig-paren">(</span><em>left</em>, <em>right</em>, <em>shape</em>, <em>dtype=&lt;class 'numpy.float32'&gt;</em>, <em>size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/random.html#random"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.random.random" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces pseudo-random numbers between left and right range.
Notice much more memory efficient than Numpy, as provides
a DTYPE argument (float32 supported).
[Added 24/11/2018] [Edited 26/11/18 Inplace operations more
memory efficient] [Edited 28/11/18 Supports complex entries]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>left</strong> (<em>Lower bound</em>)</li>
<li><strong>right</strong> (<em>Upper bound</em>)</li>
<li><strong>shape</strong> (<em>Final shape of random matrix</em>)</li>
<li><strong>dtype</strong> (<em>Data type: supports any type</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Random Vector or Matrix</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.random.uniform_vector">
<code class="descclassname">hyperlearn.random.</code><code class="descname">uniform_vector</code><span class="sig-paren">(</span><em>l</em>, <em>r</em>, <em>size</em>, <em>dtype</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/random.html#uniform_vector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.random.uniform_vector" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="hyperlearn-randomized-base-module">
<h2>hyperlearn.randomized.base module<a class="headerlink" href="#hyperlearn-randomized-base-module" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-hyperlearn.randomized.base"></span><dl class="function">
<dt id="hyperlearn.randomized.base.sketch">
<code class="descclassname">hyperlearn.randomized.base.</code><code class="descname">sketch</code><span class="sig-paren">(</span><em>n</em>, <em>p</em>, <em>k=10</em>, <em>method='left'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/base.html#sketch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.base.sketch" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a CountSketch matrix which is similar in nature to
the Johnson–Lindenstrauss Transform (eps Fast-JLT) as shown
in Sklearn. But, as shown by David Woodruff, &#8220;Sketching as a
Tool for Numerical Linear Algebra&#8221; [arxiv.org/abs/1411.4357],
super fast matrix multiplies can be done. Notice a difference
is HyperLearn&#8217;s  K = min(n, p)/2, but david says k^2/eps is
needed (too memory taxing). [Added 4/12/18] [Edited 14/12/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Data matrix.</em>)</li>
<li><strong>k</strong> (<em>(auto, int). Auto is min(n, p) / 2</em>)</li>
<li><strong>method</strong> (<em>(left, right). Left is S &#64; X. Right X &#64; S.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(Sketch Matrix S or indices)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.base.sketch_multiply">
<code class="descclassname">hyperlearn.randomized.base.</code><code class="descname">sketch_multiply</code><span class="sig-paren">(</span><em>X</em>, <em>S=None</em>, <em>k=10</em>, <em>method='left'</em>, <em>n_jobs=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/base.html#sketch_multiply"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.base.sketch_multiply" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiplies a sketch matrix S onto X either giving SX or XS.
Tries to be fast and complexity is O(np).</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.base.sketch_multiply_left">
<code class="descclassname">hyperlearn.randomized.base.</code><code class="descname">sketch_multiply_left</code><span class="sig-paren">(</span><em>X</em>, <em>S</em>, <em>k=10</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/base.html#sketch_multiply_left"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.base.sketch_multiply_left" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiplies sketch matrix S onto X giving S &#64; X.
Very fast and uses little to no memory.
[Added 14/12/18]</p>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.base.sketch_multiply_right">
<code class="descclassname">hyperlearn.randomized.base.</code><code class="descname">sketch_multiply_right</code><span class="sig-paren">(</span><em>X</em>, <em>S</em>, <em>k=10</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/base.html#sketch_multiply_right"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.base.sketch_multiply_right" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiplies sketch matrix S onto X giving X &#64; S.
Can be slow if k is small.
[Added 14/12/18]</p>
</dd></dl>

</div>
<div class="section" id="hyperlearn-randomized-linalg-module">
<h2>hyperlearn.randomized.linalg module<a class="headerlink" href="#hyperlearn-randomized-linalg-module" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-hyperlearn.randomized.linalg"></span><dl class="function">
<dt id="hyperlearn.randomized.linalg.eig">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">eig</code><span class="sig-paren">(</span><em>X</em>, <em>n_components=2</em>, <em>max_iter='auto'</em>, <em>solver='lu'</em>, <em>n_oversamples=5</em>, <em>conjugate=True</em>, <em>n_jobs=1</em>, <em>U_decision=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#eig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.eig" title="Permalink to this definition">¶</a></dt>
<dd><p>HyperLearn&#8217;s Fast Randomized Eigendecomposition is approx 20 - 40 % faster than
Sklearn&#8217;s implementation depending on n_components and max_iter.
[Added 27/11/18] [Edited 12/12/18 Added U_decision]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General Matrix.</em>)</li>
<li><strong>n_components</strong> (<em>How many eigenvectors you want.</em>)</li>
<li><strong>max_iter</strong> (<em>Default is &#8216;auto&#8217;. Can be int.</em>)</li>
<li><strong>solver</strong> (<em>(auto, lu, qr, None) Default is LU Decomposition</em>)</li>
<li><strong>n_oversamples</strong> (<em>Samples more components than necessary. Used for</em>) &#8211; convergence purposes. More is slower, but allows
better eigenvectors. Default = 5</li>
<li><strong>conjugate</strong> (<em>Whether to inplace conjugate but inplace return original.</em>)</li>
<li><strong>n_jobs</strong> (<em>Whether to use more &gt;= 1 CPU</em>)</li>
<li><strong>U_decision</strong> (<em>(False, None)</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>W</strong> (<em>Eigenvalues</em>)</li>
<li><strong>V</strong> (<em>Eigenvectors</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.linalg.eigh">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">eigh</code><span class="sig-paren">(</span><em>X</em>, <em>n_components=2</em>, <em>max_iter='auto'</em>, <em>solver='lu'</em>, <em>n_oversamples=5</em>, <em>conjugate=True</em>, <em>n_jobs=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#eigh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.eigh" title="Permalink to this definition">¶</a></dt>
<dd><p>HyperLearn&#8217;s Fast Randomized Hermitian Eigendecomposition uses
QR Orthogonal Iteration.
[Added 27/11/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General Matrix.</em>)</li>
<li><strong>n_components</strong> (<em>How many eigenvectors you want.</em>)</li>
<li><strong>max_iter</strong> (<em>Default is &#8216;auto&#8217;. Can be int.</em>)</li>
<li><strong>solver</strong> (<em>(auto, lu, qr, None) Default is LU Decomposition</em>)</li>
<li><strong>n_oversamples</strong> (<em>Samples more components than necessary. Used for</em>) &#8211; convergence purposes. More is slower, but allows
better eigenvectors. Default = 5</li>
<li><strong>conjugate</strong> (<em>Whether to inplace conjugate but inplace return original.</em>)</li>
<li><strong>n_jobs</strong> (<em>Whether to use more &gt;= 1 CPU</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>W</strong> (<em>Eigenvalues</em>)</li>
<li><strong>V</strong> (<em>Eigenvectors</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.linalg.matmul">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">matmul</code><span class="sig-paren">(</span><em>pattern</em>, <em>X</em>, <em>n_components=0.5</em>, <em>solver='euclidean'</em>, <em>n_oversamples='klogk'</em>, <em>axis=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#matmul"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.matmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Mirrors hyperlearn.linalg&#8217;s matmul functionality, but extends it by
using the randomized ColumnSelect algorithm. This can dramatically
reduce compute time, but still allows good approximate guarantees.
[Added 1/12/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>pattern</strong> (<em>Can include: X.H &#64; X | X &#64; X.H</em>)</li>
<li><strong>X</strong> (<em>Compulsory left side matrix.</em>)</li>
<li><strong>n_components</strong> (<em>(int, float). Can be a ratio of total number of</em>) &#8211; columns or rows.</li>
<li><strong>solver</strong> (<em>(euclidean, uniform, leverage, adaptive) Selects columns</em>) &#8211; based on separate squared norms of each property.</li>
<li><strong>n_oversamples</strong> (<em>(klogk, 0, k) How many extra samples is taken.</em>) &#8211; Default = k*log2(k) which guarantees (1+e)||X-X*||
error.</li>
<li><strong>axis</strong> (<em>(0, 1). Can be 0 (columns) which reduces the total</em>) &#8211; dimensionality of the data or 1 (rows) which just
reduces the compute time of forming XTX or XXT.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>out</strong> (<em>Special sketch matrix output according to pattern.</em>)</li>
<li><strong>indices</strong> (<em>Output the indices used in the sketching matrix.</em>)</li>
<li><strong>scaler</strong> (<em>Output the scaling factor by which the columns are</em>) &#8211; scaled by.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.linalg.pinv">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">pinv</code><span class="sig-paren">(</span><em>X</em>, <em>alpha=None</em>, <em>n_components='auto'</em>, <em>max_iter='auto'</em>, <em>solver='SATAX'</em>, <em>n_jobs=1</em>, <em>conjugate=True</em>, <em>converge=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#pinv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.pinv" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the Pseudoinverse of the matrix X using randomizedSVD.
Extremely fast. If n_components = &#8220;auto&#8221;, will get the top sqrt(p)+1
singular vectors.
[Added 30/11/18] [Edited 14/12/18 Added Newton Schulz and 2016 Gower&#8217;s
Linearly Convergent Randomized Pseudoinverse - R. M. Gower and Peter
Richtarik. &#8220;Linearly Convergent Randomized Iterative Methods for
Computing the Pseudoinverse&#8221;, arXiv:1612.06255]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General matrix X.</em>)</li>
<li><strong>alpha</strong> (<em>Ridge alpha regularization parameter. Default 1e-6</em>)</li>
<li><strong>n_components</strong> (<em>Default = auto. Provide less to speed things up.</em>)</li>
<li><strong>max_iter</strong> (<em>Default is &#8216;auto&#8217;. Can be int.</em>)</li>
<li><strong>solver</strong> (<em>(auto, satax, newton, sketch, lu, qr, None) Default is SATAX.</em>) &#8211; SATAX is from Gower&#8217;s 2016 paper. (lu, qr and None) use 2011
Halko&#8217;s Randomized Range Finder. Newton is Newton Schulz solver.
SKETCH is Newton + sketching.</li>
<li><strong>converge</strong> (<em>Default = True. If True, uses a newly discovered approach inspired</em>) &#8211; from Newton Schulz (inv -= 2*inv*X*inv)</li>
<li><strong>n_jobs</strong> (<em>Whether to use more &gt;= 1 CPU</em>)</li>
<li><strong>conjugate</strong> (<em>Whether to inplace conjugate but inplace return original.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>pinv(X)</strong> &#8211; pinv(X) &#64; X = I. Not exact.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Randomized Pseudoinverse of X. Approximately allows</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.linalg.proportion">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">proportion</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#proportion"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.proportion" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.linalg.qr">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">qr</code><span class="sig-paren">(</span><em>X</em>, <em>Q_only=False</em>, <em>R_only=False</em>, <em>y=None</em>, <em>n_components=2</em>, <em>solver='euclidean'</em>, <em>n_oversamples=5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#qr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.qr" title="Permalink to this definition">¶</a></dt>
<dd><p>Approximate QR Decomposition using the Gram Schmidt Process. Not very
accurate, but uses Euclidean Norm sampling from the ColumnSelect algo
to appropriately select the first columns to orthogonalise. You can
also set solver to &#8220;variance&#8221;, &#8220;correlation&#8221; or &#8220;euclidean&#8221;.
[Added 8/12/18] [Edited 12/12/18 Uses argpartititon]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General Matrix.</em>)</li>
<li><strong>y</strong> (<em>Optional. Used for &#8220;correlation&#8221; solver.</em>)</li>
<li><strong>n_components</strong> (<em>How many columns to orthogonalise. Default = 2</em>)</li>
<li><strong>solver</strong> (<em>(euclidean, variance, correlation) Which method</em>) &#8211; to choose columns. Default = euclidean.</li>
<li><strong>n_oversamples</strong> (<em>Samples more components than necessary. Used for</em>) &#8211; convergence purposes. More is slower, but allows
better eigenvectors. Default = 5</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(Q,R) or (Q) or (R) depends on option Q_only or R_only</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.linalg.randomized_projection">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">randomized_projection</code><span class="sig-paren">(</span><em>X</em>, <em>n_components=2</em>, <em>solver='lu'</em>, <em>max_iter=4</em>, <em>symmetric=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#randomized_projection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.randomized_projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Projects X onto some random eigenvectors, then using a special
variant of Orthogonal Iteration, finds the closest orthogonal
representation for X.
[Added 25/11/18] [Edited 26/11/18 Overwriting all temp variables]
[Edited 1/12/18 Added Eigh support]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General Matrix.</em>)</li>
<li><strong>n_components</strong> (<em>How many eigenvectors you want.</em>)</li>
<li><strong>solver</strong> (<em>(auto, lu, qr, None) Default is LU Decomposition</em>)</li>
<li><strong>max_iter</strong> (<em>Default is 4 iterations.</em>)</li>
<li><strong>symmetric</strong> (<em>If symmetric, reduces computation time.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">QR Decomposition of orthogonal matrix.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.linalg.select">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">select</code><span class="sig-paren">(</span><em>X</em>, <em>n_components=2</em>, <em>solver='euclidean'</em>, <em>output='columns'</em>, <em>duplicates=False</em>, <em>n_oversamples=0</em>, <em>axis=0</em>, <em>n_jobs=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#select"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.select" title="Permalink to this definition">¶</a></dt>
<dd><p>Selects columns from the matrix X using many solvers. Also
called ColumnSelect or LinearSelect, HyperLearn&#8217;s select allows
randomized algorithms to select important columns.
[Added 30/11/18] [Edited 2/12/18 Added BSS sampling]
[Edited 10/12/18 Fixed BSS Sampling]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General Matrix.</em>)</li>
<li><strong>n_components</strong> (<em>How many columns you want.</em>)</li>
<li><strong>solver</strong> (<em>(euclidean, uniform, leverage, adaptive) Selects columns</em>) &#8211; based on separate squared norms of each property.
[NEW Adaptive]. Iteratively adds parts. (Most accuarate)</li>
<li><strong>output</strong> (<em>(columns, statistics, indices) Whether to output actual</em>) &#8211; columns or just indices of the selected columns.
Also can choose statistics to get norms only.</li>
<li><strong>duplicates</strong> (<em>If True, then leaves duplicates as is. If False,</em>) &#8211; uses sqrt(count) as a scaling factor.</li>
<li><strong>n_oversamples</strong> (<em>(klogk, 0) How many extra samples is taken.</em>) &#8211; Default = 0. Not much difference.</li>
<li><strong>axis</strong> (<em>(0, 1, 2) 0 is columns. 1 is rows. 2 means both.</em>)</li>
<li><strong>n_jobs</strong> (<em>Default = 1. Whether to use &gt;= 1 CPU.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(X*, indices) Depends on output option.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="hyperlearn.randomized.linalg.svd">
<code class="descclassname">hyperlearn.randomized.linalg.</code><code class="descname">svd</code><span class="sig-paren">(</span><em>X</em>, <em>n_components=2</em>, <em>max_iter='auto'</em>, <em>solver='lu'</em>, <em>n_oversamples=5</em>, <em>U_decision=False</em>, <em>n_jobs=1</em>, <em>conjugate=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/hyperlearn/randomized/linalg.html#svd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hyperlearn.randomized.linalg.svd" title="Permalink to this definition">¶</a></dt>
<dd><p>HyperLearn&#8217;s Fast Randomized SVD is approx 20 - 40 % faster than
Sklearn&#8217;s implementation depending on n_components and max_iter.
[Added 27/11/18]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>General Matrix.</em>)</li>
<li><strong>n_components</strong> (<em>How many eigenvectors you want.</em>)</li>
<li><strong>max_iter</strong> (<em>Default is &#8216;auto&#8217;. Can be int.</em>)</li>
<li><strong>solver</strong> (<em>(auto, lu, qr, None) Default is LU Decomposition</em>)</li>
<li><strong>n_oversamples</strong> (<em>Samples more components than necessary. Used for</em>) &#8211; convergence purposes. More is slower, but allows
better eigenvectors. Default = 5</li>
<li><strong>U_decision</strong> (<em>Default = False. If True, uses max from U. If None. don&#8217;t flip.</em>)</li>
<li><strong>n_jobs</strong> (<em>Whether to use more &gt;= 1 CPU</em>)</li>
<li><strong>conjugate</strong> (<em>Whether to inplace conjugate but inplace return original.</em>)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>U</strong> (<em>Orthogonal Left Eigenvectors</em>)</li>
<li><strong>S</strong> (<em>Descending Singular Values</em>)</li>
<li><strong>VT</strong> (<em>Orthogonal Right Eigenvectors</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-hyperlearn">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-hyperlearn" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../base.html" class="btn btn-neutral float-right" title="hyperlearn.base" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="modules.html" class="btn btn-neutral" title="hyperlearn" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Daniel Han-Chen

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'1',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: ''
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>